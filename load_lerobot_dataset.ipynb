{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98d0402d",
   "metadata": {},
   "source": [
    "# LeRobot Dataset Loading Tutorial\n",
    "\n",
    "This notebook demonstrates how to use the `LeRobotDataset` class for handling and processing robotic datasets from Hugging Face. It covers:\n",
    "\n",
    "- Viewing dataset metadata and exploring properties\n",
    "- Loading datasets from the hub or subsets\n",
    "- Accessing frames by episode number\n",
    "- Using advanced features like timestamp-based frame selection\n",
    "- Demonstrating compatibility with PyTorch DataLoader for batch processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940090dd",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "First, let's import all the necessary libraries for working with LeRobot datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858a2d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "import lerobot\n",
    "from lerobot.common.datasets.lerobot_dataset import (\n",
    "    LeRobotDataset,\n",
    "    LeRobotDatasetMetadata,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3599d7",
   "metadata": {},
   "source": [
    "## Discover Available Datasets\n",
    "\n",
    "Let's explore what datasets are available, including both built-in datasets and community hub datasets. We'll specifically look for Kuka robot datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91d3b1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total datasets: 9823, Kuka datasets: '\n",
      " \"['lerobot/stanford_kuka_multimodal_dataset', \"\n",
      " \"'lerobot/stanford_kuka_multimodal_dataset', \"\n",
      " \"'aliberts/stanford_kuka_multimodal_dataset', 'IPEC-COMMUNITY/kuka_lerobot', \"\n",
      " \"'zjc020603/kuka_single_arm', 'chuanmew/kuka_lerobot']\")\n"
     ]
    }
   ],
   "source": [
    "# Get all available datasets (built-in + community hub)\n",
    "hub_api = HfApi()\n",
    "all_datasets = lerobot.available_datasets + [\n",
    "    info.id\n",
    "    for info in hub_api.list_datasets(task_categories=\"robotics\", tags=[\"LeRobot\"])\n",
    "]\n",
    "kuka_datasets = [repo_id for repo_id in all_datasets if \"kuka\" in repo_id.lower()]\n",
    "pprint(f\"Total datasets: {len(all_datasets)}, Kuka datasets: {kuka_datasets}\")\n",
    "\n",
    "# Or simply explore them in your web browser directly at:\n",
    "# https://huggingface.co/datasets?other=LeRobot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee421579",
   "metadata": {},
   "source": [
    "## Explore Dataset Metadata\n",
    "\n",
    "Before downloading the actual data, we can examine the dataset's metadata to understand its structure and properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2b0433d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of episodes: 3000\n",
      "Average number of frames per episode: 49.995\n",
      "Frames per second used during data collection: 20\n",
      "Robot type: unknown\n",
      "keys to access images from cameras: ds_meta.camera_keys=['observation.images.image']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's take this one for this example\n",
    "repo_id = \"lerobot/stanford_kuka_multimodal_dataset\"\n",
    "# We can have a look and fetch its metadata to know more about it:\n",
    "ds_meta = LeRobotDatasetMetadata(repo_id)\n",
    "\n",
    "# By instantiating just this class, you can quickly access useful information about the content and the\n",
    "# structure of the dataset without downloading the actual data yet (only metadata files â€” which are\n",
    "# lightweight).\n",
    "print(f\"Total number of episodes: {ds_meta.total_episodes}\")\n",
    "print(\n",
    "    f\"Average number of frames per episode: {ds_meta.total_frames / ds_meta.total_episodes:.3f}\"\n",
    ")\n",
    "print(f\"Frames per second used during data collection: {ds_meta.fps}\")\n",
    "print(f\"Robot type: {ds_meta.robot_type}\")\n",
    "print(f\"keys to access images from cameras: {ds_meta.camera_keys=}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d11de500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasks:\n",
      "{0: 'insert the peg into the hole'}\n",
      "Features:\n",
      "{'action': {'dtype': 'float32',\n",
      "            'names': {'motors': ['motor_0',\n",
      "                                 'motor_1',\n",
      "                                 'motor_2',\n",
      "                                 'motor_3',\n",
      "                                 'motor_4',\n",
      "                                 'motor_5',\n",
      "                                 'motor_6']},\n",
      "            'shape': (7,)},\n",
      " 'episode_index': {'dtype': 'int64', 'names': None, 'shape': (1,)},\n",
      " 'frame_index': {'dtype': 'int64', 'names': None, 'shape': (1,)},\n",
      " 'index': {'dtype': 'int64', 'names': None, 'shape': (1,)},\n",
      " 'next.done': {'dtype': 'bool', 'names': None, 'shape': (1,)},\n",
      " 'next.reward': {'dtype': 'float32', 'names': None, 'shape': (1,)},\n",
      " 'observation.images.image': {'dtype': 'video',\n",
      "                              'names': ['height', 'width', 'channel'],\n",
      "                              'shape': (128, 128, 3),\n",
      "                              'video_info': {'has_audio': False,\n",
      "                                             'video.codec': 'av1',\n",
      "                                             'video.fps': 20.0,\n",
      "                                             'video.is_depth_map': False,\n",
      "                                             'video.pix_fmt': 'yuv420p'}},\n",
      " 'observation.state': {'dtype': 'float32',\n",
      "                       'names': {'motors': ['motor_0',\n",
      "                                            'motor_1',\n",
      "                                            'motor_2',\n",
      "                                            'motor_3',\n",
      "                                            'motor_4',\n",
      "                                            'motor_5',\n",
      "                                            'motor_6']},\n",
      "                       'shape': (7,)},\n",
      " 'task_index': {'dtype': 'int64', 'names': None, 'shape': (1,)},\n",
      " 'timestamp': {'dtype': 'float32', 'names': None, 'shape': (1,)}}\n",
      "LeRobotDatasetMetadata({\n",
      "    Repository ID: 'lerobot/stanford_kuka_multimodal_dataset',\n",
      "    Total episodes: '3000',\n",
      "    Total frames: '149985',\n",
      "    Features: '['observation.images.image', 'observation.state', 'action', 'timestamp', 'episode_index', 'frame_index', 'next.reward', 'next.done', 'index', 'task_index']',\n",
      "})',\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Tasks:\")\n",
    "print(ds_meta.tasks)\n",
    "print(\"Features:\")\n",
    "pprint(ds_meta.features)\n",
    "\n",
    "# You can also get a short summary by simply printing the object:\n",
    "print(ds_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bca78c1",
   "metadata": {},
   "source": [
    "## Load Dataset Subsets\n",
    "\n",
    "You can load specific episodes from the dataset instead of downloading the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "771ea665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected episodes: [0, 10, 11, 23]\n",
      "Number of episodes selected: 4\n",
      "Number of frames selected: 200\n"
     ]
    }
   ],
   "source": [
    "# You can then load the actual dataset from the hub.\n",
    "# Either load any subset of episodes:\n",
    "dataset = LeRobotDataset(repo_id, episodes=[0, 10, 11, 23])\n",
    "\n",
    "# And see how many frames you have:\n",
    "print(f\"Selected episodes: {dataset.episodes}\")\n",
    "print(f\"Number of episodes selected: {dataset.num_episodes}\")\n",
    "print(f\"Number of frames selected: {dataset.num_frames}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823d1373",
   "metadata": {},
   "source": [
    "## Load Complete Dataset\n",
    "\n",
    "Alternatively, you can load the entire dataset at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04ccadb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "682a504d9d4a4afeb4b7375e6d193864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of episodes selected: 3000\n",
      "Number of frames selected: 149985\n",
      "LeRobotDatasetMetadata({\n",
      "    Repository ID: 'lerobot/stanford_kuka_multimodal_dataset',\n",
      "    Total episodes: '3000',\n",
      "    Total frames: '149985',\n",
      "    Features: '['observation.images.image', 'observation.state', 'action', 'timestamp', 'episode_index', 'frame_index', 'next.reward', 'next.done', 'index', 'task_index']',\n",
      "})',\n",
      "\n",
      "Dataset({\n",
      "    features: ['observation.state', 'action', 'timestamp', 'episode_index', 'frame_index', 'next.reward', 'next.done', 'index', 'task_index'],\n",
      "    num_rows: 149985\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Or simply load the entire dataset:\n",
    "dataset = LeRobotDataset(repo_id)\n",
    "print(f\"Number of episodes selected: {dataset.num_episodes}\")\n",
    "print(f\"Number of frames selected: {dataset.num_frames}\")\n",
    "\n",
    "# The previous metadata class is contained in the 'meta' attribute of the dataset:\n",
    "print(dataset.meta)\n",
    "\n",
    "# LeRobotDataset actually wraps an underlying Hugging Face dataset\n",
    "# (see https://huggingface.co/docs/datasets for more information).\n",
    "print(dataset.hf_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b56b1f4",
   "metadata": {},
   "source": [
    "## Access Individual Frames and Episodes\n",
    "\n",
    "LeRobot datasets are PyTorch-compatible, so you can iterate through them and access individual frames. Let's examine frames from the first episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8494c8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([3, 128, 128])\n",
      "{'dtype': 'video',\n",
      " 'names': ['height', 'width', 'channel'],\n",
      " 'shape': (128, 128, 3),\n",
      " 'video_info': {'has_audio': False,\n",
      "                'video.codec': 'av1',\n",
      "                'video.fps': 20.0,\n",
      "                'video.is_depth_map': False,\n",
      "                'video.pix_fmt': 'yuv420p'}}\n",
      "(128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "# LeRobot datasets also subclasses PyTorch datasets so you can do everything you know and love from working\n",
    "# with the latter, like iterating through the dataset.\n",
    "# The __getitem__ iterates over the frames of the dataset. Since our datasets are also structured by\n",
    "# episodes, you can access the frame indices of any episode using the episode_data_index. Here, we access\n",
    "# frame indices associated to the first episode:\n",
    "episode_index = 0\n",
    "from_idx = dataset.episode_data_index[\"from\"][episode_index].item()\n",
    "to_idx = dataset.episode_data_index[\"to\"][episode_index].item()\n",
    "\n",
    "# Then we grab all the image frames from the first camera:\n",
    "camera_key = dataset.meta.camera_keys[0]\n",
    "frames = [dataset[idx][camera_key] for idx in range(from_idx, to_idx)]\n",
    "\n",
    "# The objects returned by the dataset are all torch.Tensors\n",
    "print(type(frames[0]))\n",
    "print(frames[0].shape)\n",
    "\n",
    "# Since we're using pytorch, the shape is in pytorch, channel-first convention (c, h, w).\n",
    "# We can compare this shape with the information available for that feature\n",
    "pprint(dataset.features[camera_key])\n",
    "# In particular:\n",
    "print(dataset.features[camera_key][\"shape\"])\n",
    "# The shape is in (h, w, c) which is a more universal format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc83b75",
   "metadata": {},
   "source": [
    "## Advanced: Loading Temporal Data\n",
    "\n",
    "For many machine learning applications, you need to load the history of past observations or trajectories of future actions. LeRobot datasets support loading previous and future frames using timestamp differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a379b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For many machine learning applications we need to load the history of past observations or trajectories of\n",
    "# future actions. Our datasets can load previous and future frames for each key/modality, using timestamps\n",
    "# differences with the current loaded frame. For instance:\n",
    "delta_timestamps = {\n",
    "    # loads 4 images: 1 second before current frame, 500 ms before, 200 ms before, and current frame\n",
    "    camera_key: [-1, -0.5, -0.20, 0],\n",
    "    # loads 6 state vectors: 1.5 seconds before, 1 second before, ... 200 ms, 100 ms, and current frame\n",
    "    \"observation.state\": [-1.5, -1, -0.5, -0.20, -0.10, 0],\n",
    "    # loads 64 action vectors: current frame, 1 frame in the future, 2 frames, ... 63 frames in the future\n",
    "    \"action\": [t / dataset.fps for t in range(64)],\n",
    "}\n",
    "# Note that in any case, these delta_timestamps values need to be multiples of (1/fps) so that added to any\n",
    "# timestamp, you still get a valid timestamp.\n",
    "\n",
    "dataset = LeRobotDataset(repo_id, delta_timestamps=delta_timestamps)\n",
    "print(f\"\\n{dataset[0][camera_key].shape=}\")  # (4, c, h, w)\n",
    "print(f\"{dataset[0]['observation.state'].shape=}\")  # (6, c)\n",
    "print(f\"{dataset[0]['action'].shape=}\\n\")  # (64, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c38f7ed",
   "metadata": {},
   "source": [
    "## PyTorch DataLoader Integration\n",
    "\n",
    "LeRobot datasets are fully compatible with PyTorch DataLoaders and samplers, making them easy to integrate into your machine learning training pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f045007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, our datasets are fully compatible with PyTorch dataloaders and samplers because they are just\n",
    "# PyTorch datasets.\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    num_workers=0,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(f\"{batch[camera_key].shape=}\")  # (32, 4, c, h, w)\n",
    "    print(f\"{batch['observation.state'].shape=}\")  # (32, 6, c)\n",
    "    print(f\"{batch['action'].shape=}\")  # (32, 64, c)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad17864e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the key features of LeRobot datasets:\n",
    "\n",
    "1. **Dataset Discovery**: Finding available datasets on Hugging Face Hub\n",
    "2. **Metadata Exploration**: Understanding dataset structure without downloading data\n",
    "3. **Flexible Loading**: Loading complete datasets or specific episodes\n",
    "4. **Frame Access**: Accessing individual frames and episodes\n",
    "5. **Temporal Data**: Loading sequences of past/future observations and actions\n",
    "6. **PyTorch Integration**: Using datasets with PyTorch DataLoaders for training\n",
    "\n",
    "LeRobot datasets provide a powerful and flexible way to work with robotic datasets, whether you're doing research, training models, or exploring robotic data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
