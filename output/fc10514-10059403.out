warning: The `extra-build-dependencies` option is experimental and may change without warning. Pass `--preview-features extra-build-dependencies` to disable this warning.
INFO 2025-11-01 19:29:00 ot_train.py:163 {'batch_size': 32,
 'checkpoint_path': None,
 'dataset': {'episodes': None,
             'image_transforms': {'enable': False,
                                  'max_num_transforms': 3,
                                  'random_order': False,
                                  'tfs': {'affine': {'kwargs': {'degrees': [-5.0,
                                                                            5.0],
                                                                'translate': [0.05,
                                                                              0.05]},
                                                     'type': 'RandomAffine',
                                                     'weight': 1.0},
                                          'brightness': {'kwargs': {'brightness': [0.8,
                                                                                   1.2]},
                                                         'type': 'ColorJitter',
                                                         'weight': 1.0},
                                          'contrast': {'kwargs': {'contrast': [0.8,
                                                                               1.2]},
                                                       'type': 'ColorJitter',
                                                       'weight': 1.0},
                                          'hue': {'kwargs': {'hue': [-0.05,
                                                                     0.05]},
                                                  'type': 'ColorJitter',
                                                  'weight': 1.0},
                                          'saturation': {'kwargs': {'saturation': [0.5,
                                                                                   1.5]},
                                                         'type': 'ColorJitter',
                                                         'weight': 1.0},
                                          'sharpness': {'kwargs': {'sharpness': [0.5,
                                                                                 1.5]},
                                                        'type': 'SharpnessJitter',
                                                        'weight': 1.0}}},
             'repo_id': '/home/rayen/scratch/lerobot/datasets/youliangtan-so101-table-cleanup',
             'revision': None,
             'root': None,
             'streaming': False,
             'use_imagenet_stats': True,
             'video_backend': 'torchcodec'},
 'env': None,
 'eval': {'batch_size': 50, 'n_episodes': 50, 'use_async_envs': False},
 'eval_freq': 20000,
 'job_name': 'groot_n1.5_youliangtan-so101-table-cleanup_bs32_lr0.0001_20251101_192851',
 'log_freq': 200,
 'num_workers': 4,
 'optimizer': {'betas': [0.95, 0.999],
               'eps': 1e-08,
               'grad_clip_norm': 10.0,
               'lr': 0.0001,
               'type': 'adamw',
               'weight_decay': 1e-05},
 'output_dir': 'outputs/train/groot_n1.5_youliangtan-so101-table-cleanup_bs32_lr0.0001_20251101_192851',
 'policy': {'balance_dataset_weights': True,
            'balance_trajectory_weights': True,
            'base_model_path': 'nvidia/GR00T-N1.5-3B',
            'batch_size': 32,
            'chunk_size': 50,
            'dataloader_num_workers': 8,
            'dataset_paths': None,
            'device': 'cuda',
            'embodiment_tag': 'new_embodiment',
            'image_size': [224, 224],
            'input_features': {},
            'license': None,
            'lora_alpha': 16,
            'lora_dropout': 0.1,
            'lora_full_model': False,
            'lora_rank': 0,
            'max_action_dim': 32,
            'max_state_dim': 64,
            'max_steps': 10000,
            'n_action_steps': 50,
            'n_obs_steps': 1,
            'normalization_mapping': {'ACTION': <NormalizationMode.MEAN_STD: 'MEAN_STD'>,
                                      'STATE': <NormalizationMode.MEAN_STD: 'MEAN_STD'>,
                                      'VISUAL': <NormalizationMode.IDENTITY: 'IDENTITY'>},
            'optimizer_betas': [0.95, 0.999],
            'optimizer_eps': 1e-08,
            'optimizer_lr': 0.0001,
            'optimizer_weight_decay': 1e-05,
            'output_dir': './tmp/gr00t',
            'output_features': {},
            'pretrained_path': None,
            'private': None,
            'push_to_hub': False,
            'repo_id': None,
            'report_to': 'wandb',
            'resume': False,
            'save_steps': 1000,
            'tags': None,
            'tokenizer_assets_repo': 'lerobot/eagle2hg-processor-groot-n1p5',
            'tune_diffusion_model': True,
            'tune_llm': False,
            'tune_projector': True,
            'tune_visual': False,
            'type': 'groot',
            'use_amp': False,
            'use_bf16': True,
            'video_backend': 'decord',
            'warmup_ratio': 0.05},
 'rename_map': {},
 'resume': False,
 'save_checkpoint': True,
 'save_freq': 5000,
 'scheduler': {'decay_lr': 1e-05,
               'num_decay_steps': 10000,
               'num_warmup_steps': 500,
               'peak_lr': 0.0001,
               'type': 'cosine_decay_with_warmup'},
 'seed': 1000,
 'steps': 10000,
 'use_policy_training_preset': True,
 'wandb': {'disable_artifact': False,
           'enable': True,
           'entity': None,
           'mode': None,
           'notes': None,
           'project': 'lerobot',
           'run_id': None}}
/scratch/rayen/lerobot/.venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/scratch/rayen/lerobot/.venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
INFO 2025-11-01 19:29:01 db_utils.py:104 Logs will be synced with wandb.
INFO 2025-11-01 19:29:01 db_utils.py:105 Track this run --> https://wandb.ai/rayenghali02-university-of-moncton/lerobot/runs/rb3inzax
INFO 2025-11-01 19:29:01 ot_train.py:183 Creating dataset
INFO 2025-11-01 19:29:02 ot_train.py:202 Creating policy
[GROOT] Flash Attention version: 2.8.3
Loading pretrained dual brain from nvidia/GR00T-N1.5-3B
Tune backbone vision tower: False
Tune backbone LLM: False
Tune action head projector: True
Tune action head DiT: True
Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]Fetching 13 files: 100%|██████████| 13/13 [00:00<00:00, 156683.77it/s]
INFO 2025-11-01 19:29:04 le2_5_vl.py:105 min_dynamic_tiles: 1
INFO 2025-11-01 19:29:04 le2_5_vl.py:106 max_dynamic_tiles: 12
INFO 2025-11-01 19:29:04 gle2_5_vl.py:64 vision_config is None. Initializing the InternVisionConfig with default values.
INFO 2025-11-01 19:29:04 gle2_5_vl.py:68 text_config is None. Initializing the LlamaConfig config with default values (`LlamaConfig`).
INFO 2025-11-01 19:29:04 le2_5_vl.py:105 min_dynamic_tiles: 1
INFO 2025-11-01 19:29:04 le2_5_vl.py:106 max_dynamic_tiles: 6
INFO 2025-11-01 19:29:05 le2_5_vl.py:101 num_image_token: 256
INFO 2025-11-01 19:29:05 le2_5_vl.py:102 mlp_checkpoint: False
[GROOT] Copying vendor Eagle files to cache: /scratch/rayen/lerobot/src/lerobot/policies/groot/eagle2_hg_model -> /home/rayen/.cache/huggingface/lerobot/lerobot/eagle2hg-processor-groot-n1p5
[GROOT] Assets repo: lerobot/eagle2hg-processor-groot-n1p5 
 Cache dir: /home/rayen/.cache/huggingface/lerobot/lerobot/eagle2hg-processor-groot-n1p5
[GROOT] Fetching vocab.json
[GROOT] Fetching merges.txt
[GROOT] Fetching added_tokens.json
[GROOT] Fetching chat_template.json
[GROOT] Fetching special_tokens_map.json
[GROOT] Fetching config.json
[GROOT] Fetching generation_config.json
[GROOT] Fetching preprocessor_config.json
[GROOT] Fetching processor_config.json
[GROOT] Fetching tokenizer_config.json
Tune backbone llm: False
Tune backbone visual: True
Total number of DiT parameters:  550386688
Total number of SelfAttentionTransformer parameters:  201433088
Tune action head projector: True
Tune action head diffusion model: True
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  3.62it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.00it/s]
INFO 2025-11-01 19:29:10 ot_train.py:247 Creating optimizer and scheduler
INFO 2025-11-01 19:29:10 ot_train.py:259 Output dir: outputs/train/groot_n1.5_youliangtan-so101-table-cleanup_bs32_lr0.0001_20251101_192851
INFO 2025-11-01 19:29:10 ot_train.py:262 cfg.steps=10000 (10K)
INFO 2025-11-01 19:29:10 ot_train.py:263 dataset.num_frames=46963 (47K)
INFO 2025-11-01 19:29:10 ot_train.py:264 dataset.num_episodes=80
INFO 2025-11-01 19:29:10 ot_train.py:267 Effective batch size: 32 x 1 = 32
INFO 2025-11-01 19:29:10 ot_train.py:268 num_learnable_params=1068806144 (1B)
INFO 2025-11-01 19:29:10 ot_train.py:269 num_total_params=2724163520 (3B)
/scratch/rayen/lerobot/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
INFO 2025-11-01 19:29:10 ot_train.py:324 Start offline training on a fixed dataset
Tune backbone llm: False
Tune backbone visual: False
Warning: No backbone trainable parameters found.
Tune action head projector: True
Tune action head diffusion model: True
`use_fast` is set to `True` but the image processor class does not have a fast version.  Falling back to the slow version.
Traceback (most recent call last):
  File "/scratch/rayen/lerobot/.venv/bin/lerobot-train", line 10, in <module>
    sys.exit(main())
             ^^^^^^
  File "/scratch/rayen/lerobot/src/lerobot/scripts/lerobot_train.py", line 444, in main
    train()
  File "/scratch/rayen/lerobot/src/lerobot/configs/parser.py", line 233, in wrapper_inner
    response = fn(cfg, *args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/rayen/lerobot/src/lerobot/scripts/lerobot_train.py", line 332, in train
    train_tracker, output_dict = update_policy(
                                 ^^^^^^^^^^^^^^
  File "/scratch/rayen/lerobot/src/lerobot/scripts/lerobot_train.py", line 91, in update_policy
    loss, output_dict = policy.forward(batch)
                        ^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/rayen/lerobot/src/lerobot/policies/groot/modeling_groot.py", line 114, in forward
    outputs = self._groot_model.forward(groot_inputs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/rayen/lerobot/src/lerobot/policies/groot/groot_n1.py", line 303, in forward
    backbone_inputs, action_inputs = self.prepare_input(inputs)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/rayen/lerobot/src/lerobot/policies/groot/groot_n1.py", line 339, in prepare_input
    backbone_inputs = tree.map_structure(to_device_with_maybe_dtype, backbone_inputs)
                      ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'map_structure'
